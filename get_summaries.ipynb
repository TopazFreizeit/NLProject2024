{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_question(text):\n",
    "        questions = text.split('Question:')[1:]\n",
    "        if questions:\n",
    "            last_question = questions[-1].strip()\n",
    "            # Split at 'Correct Answer' and take the first part\n",
    "            question_and_options = last_question.split('Correct Answer:')[0].strip()\n",
    "            return f\"Question: {question_and_options}\"\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "df = pd.read_csv('all.csv')\n",
    "df['new_prompt'] = df['prompt'].apply(get_last_question)\n",
    "df.to_csv('new_prompt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m prompts \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 24\u001b[0m     summaries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m summaries\n\u001b[1;32m     26\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_file_with_summaries.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "system_message = \"You are a medical expert analyzing exam questions. Describe the key medical concepts without answering the question. dont write any unrelated information. dont include introduction and start directly with the answer . \"\n",
    "\n",
    "def process_prompt(prompt):\n",
    "    response = ollama.generate(\n",
    "                model='llama3:8b',\n",
    "                system=system_message,\n",
    "                prompt=f\"\"\"describe in one sentence the medical concepts being tested in the following question. don't try to answer the question.:\n",
    "\n",
    "{prompt}\n",
    "\n",
    "The medical concepts being tested in this question include: \"\"\"\n",
    "    )\n",
    "    return response['response']\n",
    "\n",
    "\n",
    "df = pd.read_csv('new_prompt.csv')\n",
    "prompts = df['new_prompt'].tolist()\n",
    "# Create a progress bar\n",
    "with tqdm(total=len(prompts), desc=\"Processing prompts\") as pbar:\n",
    "    def process_and_update(prompt):\n",
    "        result = process_prompt(prompt)\n",
    "        pbar.update(1)\n",
    "        return result\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        summaries = list(executor.map(process_and_update, prompts))\n",
    "\n",
    "df['summary'] = summaries\n",
    "df.to_csv('output_file_with_summaries.csv', index=False)\n",
    "df['summary'] = summaries\n",
    "df.to_csv('output_file_with_summaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts: 100%|██████████| 10175/10175 [2:49:25<00:00,  1.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to 'output_file_with_summaries.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "BATCH_SIZE = 10  # You can adjust this value based on your needs\n",
    "\n",
    "system_message = \"You are a medical expert analyzing exam questions. Describe the key medical concepts without answering the question. dont write any unrelated information. dont include introduction and start directly with the answer . \"\n",
    "\n",
    "def process_prompt(prompt):\n",
    "    response = ollama.generate(\n",
    "                model='llama3:8b',\n",
    "                system=system_message,\n",
    "                prompt=f\"\"\"describe in one sentence the medical concepts being tested in the following question. don't try to answer the question.:\n",
    "\n",
    "{prompt}\n",
    "\n",
    "The medical concepts being tested in this question include: \"\"\"\n",
    "    )\n",
    "    return response['response']\n",
    "\n",
    "def process_batch(batch):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        return list(executor.map(process_prompt, batch))\n",
    "\n",
    "# Read the input CSV file\n",
    "df = pd.read_csv('new_prompt.csv')\n",
    "total_rows = len(df)\n",
    "\n",
    "# Create a progress bar\n",
    "with tqdm(total=total_rows, desc=\"Processing prompts\") as pbar:\n",
    "    for start_idx in range(0, total_rows, BATCH_SIZE):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, total_rows)\n",
    "        \n",
    "        # Process the current batch\n",
    "        batch = df.loc[start_idx:end_idx-1, 'new_prompt'].tolist()\n",
    "        summaries = process_batch(batch)\n",
    "        \n",
    "        # Update the DataFrame with the new summaries\n",
    "        df.loc[start_idx:end_idx-1, 'summary'] = summaries\n",
    "        \n",
    "        # Save the current batch to the CSV file\n",
    "        if start_idx == 0:\n",
    "            df.loc[start_idx:end_idx-1].to_csv('output_file_with_summaries.csv', index=False, mode='w')\n",
    "        else:\n",
    "            df.loc[start_idx:end_idx-1].to_csv('output_file_with_summaries.csv', index=False, mode='a', header=False)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        pbar.update(end_idx - start_idx)\n",
    "\n",
    "print(\"Processing complete. Results saved to 'output_file_with_summaries.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt', 'biomistral', 'meditron', 'medalpaca', 'new_prompt',\n",
      "       'summary'],\n",
      "      dtype='object')\n",
      "Index(['prompt', 'biomistral', 'meditron', 'medalpaca', 'correct_answer',\n",
      "       'best_model', 'highest_probability', 'processed_prompt', 'tokens'],\n",
      "      dtype='object')\n",
      "10175 10034\n",
      "10034\n",
      "                                             summary  \\\n",
      "0  The key medical concepts being tested in this ...   \n",
      "1  The medical concepts being tested in this ques...   \n",
      "2  The medical concepts being tested in this ques...   \n",
      "3  The key medical concepts being tested in this ...   \n",
      "4  The key medical concepts being tested in this ...   \n",
      "\n",
      "                                              prompt correct_answer  \\\n",
      "0  The following are multiple choice questions (w...              B   \n",
      "1  The following are multiple choice questions (w...              C   \n",
      "2  The following are multiple choice questions (w...              C   \n",
      "3  The following are multiple choice questions (w...              A   \n",
      "4  The following are multiple choice questions (w...              B   \n",
      "\n",
      "   best_model  \n",
      "0  biomistral  \n",
      "1  biomistral  \n",
      "2    meditron  \n",
      "3  biomistral  \n",
      "4  biomistral  \n"
     ]
    }
   ],
   "source": [
    "df1 = df\n",
    "df2 = pd.read_csv('mcq_data_with_custom_ner_tags_cleaned.csv')\n",
    "print(df1.columns)\n",
    "print(df2.columns)\n",
    "print(len(df1), len(df2))\n",
    "merged_df = pd.merge(df1[['biomistral', 'meditron', 'medalpaca', 'summary', 'prompt']],\n",
    "                     df2[['biomistral', 'meditron', 'medalpaca', 'correct_answer', ]],\n",
    "                     on=['biomistral', 'meditron', 'medalpaca'],\n",
    "                     how='inner')\n",
    "\n",
    "# Select only the required columns\n",
    "result_df = merged_df[['summary', 'prompt', 'correct_answer', 'best_model']]\n",
    "\n",
    "print(len(result_df))\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the input CSV file\n",
    "df1 = pd.read_csv('output_file_with_summaries.csv')\n",
    "df2 = pd.read_csv('mcq_data_with_custom_ner_tags_cleaned.csv')\n",
    "\n",
    "merged_df = pd.merge(df1[['biomistral', 'meditron', 'medalpaca', 'summary', 'prompt']],\n",
    "                     df2[['biomistral', 'meditron', 'medalpaca', 'correct_answer', ]],\n",
    "                     on=['biomistral', 'meditron', 'medalpaca'],\n",
    "                     how='inner')\n",
    "\n",
    "# Select only the required columns\n",
    "result_df = merged_df[['summary', 'prompt', 'correct_answer', 'biomistral', 'meditron', 'medalpaca']]\n",
    "\n",
    "result_df.to_csv('summary_models_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['summary', 'prompt', 'correct_answer', 'biomistral', 'meditron',\n",
       "       'medalpaca'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('summary_models_probabilities_correct_answer.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def get_highest_prob_char(model_output):\n",
    "    return max(ast.literal_eval(model_output), key=ast.literal_eval(model_output).get)\n",
    "\n",
    "def check_models(row):\n",
    "    models = ['biomistral', 'meditron', 'medalpaca']\n",
    "    correct_models = []\n",
    "    correct_ids = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        if get_highest_prob_char(row[model]) == row['correct_answer']:\n",
    "            correct_models.append(model)\n",
    "            correct_ids.append(i)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'models_are_correct': correct_models,\n",
    "        'ids_are_correct': correct_ids\n",
    "    })\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Apply the function to create new columns\n",
    "df[['models_are_correct', 'ids_are_correct']] = df.apply(check_models, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('summary_models_are_correct.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
